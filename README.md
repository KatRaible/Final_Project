Final Project: Data Analytics & Engineering with Python


Welcome to our team's final project! In this project, we demonstrate our skills in setting up a robust data pipeline, performing in-depth Exploratory Data Analysis (EDA), and presenting actionable insights derived from real-time data sourced from the UK Open Rail Data API.


Data Pipeline
Our team has meticulously crafted a data pipeline using Docker, Kafka, and Spark to ensure the seamless ingestion, transformation, and storage of live data from the UK Open Rail Data API. This pipeline facilitates the continuous flow of real-time data into a PostgreSQL database, hosted on Amazon Web Services (AWS), providing a rich source for analysis and insights generation.


EDA
Exploratory Data Analysis (EDA) forms the core of our project, where we delve deep into the data to uncover meaningful patterns, trends, and insights. Leveraging Jupyter notebooks, we conduct comprehensive analyses, perform data cleaning, and visualize key metrics to gain a holistic understanding of the railway data ecosystem. Our EDA journey began with a sample dataset, serving as a foundation for our analyses. This dataset, in the parquet file format, closely resembles the real-time data obtained from our pipeline.



Our Approach to EDA
Actions Taken:

-Leveraged Jupyter notebooks to load data from the PostgreSQL database and conduct EDA.
-Executed a comprehensive EDA process, covering data cleaning, exploration, visualization, and interpretation.
-Consolidated our findings into a comprehensive document, catering to both technical and non-technical stakeholders.
-Merged the Station Rail Name Reference Table with the API data to enhance data readability.
-Conducted in-depth analysis to uncover factors contributing to train delays, enabling us to identify optimization opportunities.
-Analyzed station traffic patterns across different time intervals, providing insights for effective resource allocation strategies.



(README.md)